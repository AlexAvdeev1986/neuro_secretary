import os
import logging
import hashlib
from dotenv import load_dotenv
import openai
import whisper
import noisereduce as nr
import soundfile as sf
import numpy as np
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
WHISPER_MODEL = whisper.load_model("base")  # –û–¥–Ω–æ–∫—Ä–∞—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
GPT_MODEL = "gpt-4-turbo-preview"
MAX_AUDIO_DURATION = 60 * 60 * 2  # 2 —á–∞—Å–∞

def clean_audio(input_file: str, output_file: str) -> None:
    """–û—á–∏—Å—Ç–∫–∞ –∞—É–¥–∏–æ –æ—Ç —à—É–º–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
    try:
        data, rate = sf.read(input_file)
        if len(data) == 0:
            raise ValueError("–ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª")
            
        reduced_noise = nr.reduce_noise(y=data, sr=rate)
        sf.write(output_file, reduced_noise, rate)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∞—É–¥–∏–æ: {e}")
        raise

def transcribe_audio(audio_file: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    try:
        info = sf.info(audio_file)
        if info.duration > MAX_AUDIO_DURATION:
            raise ValueError(f"–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ ({info.duration}s > {MAX_AUDIO_DURATION}s)")
            
        result = WHISPER_MODEL.transcribe(audio_file)
        return result["text"]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}")
        raise

def analyze_text(text: str) -> str:
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ API"""
    try:
        response = openai.ChatCompletion.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç —Å–æ–≤–µ—â–∞–Ω–∏—è. –í—ã–¥–µ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, –≤–æ–ø—Ä–æ—Å—ã, —Ä–µ—à–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö."},
                {"role": "user", "content": text}
            ],
            temperature=0.2,
            max_tokens=3000
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
        raise

def generate_protocol(analysis_result: str) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    cache_dir = "cache"
    os.makedirs(cache_dir, exist_ok=True)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    hash_object = hashlib.md5(analysis_result.encode())
    cache_file = os.path.join(cache_dir, f"{hash_object.hexdigest()}.txt")
    
    if os.path.exists(cache_file):
        with open(cache_file, "r") as f:
            return f.read()
    
    try:
        response = openai.ChatCompletion.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": "–°–æ–∑–¥–∞–π –ø—Ä–æ—Ç–æ–∫–æ–ª —Å–æ–≤–µ—â–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."},
                {"role": "user", "content": analysis_result}
            ],
            temperature=0.5,
            max_tokens=3000
        )
        result = response['choices'][0]['message']['content']
        
        with open(cache_file, "w") as f:
            f.write(result)
            
        return result
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        raise

async def handle_audio(update: Update, context) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        user = update.message.from_user
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ –∞—É–¥–∏–æ –æ—Ç {user.username} ({user.id})")
        
        file = await update.message.audio.get_file()
        file_hash = hashlib.md5(file.file_id.encode()).hexdigest()
        input_file = f"temp_{file_hash}.wav"
        
        await file.download_to_drive(input_file)
        
        # –û—á–∏—Å—Ç–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
        clean_audio(input_file, input_file)
        transcript = transcribe_audio(input_file)
        
        # –ê–Ω–∞–ª–∏–∑ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        analysis = analyze_text(transcript)
        protocol = generate_protocol(analysis)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        await update.message.reply_text(
            f"‚úÖ –ü—Ä–æ—Ç–æ–∫–æ–ª —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω:\n\n{protocol}",
            parse_mode="Markdown"
        )
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        os.remove(input_file)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

async def start(update: Update, context) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    await update.message.reply_text(
        "ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ NeuroSecretary!\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –∑–∞–ø–∏—Å—å—é —Å–æ–≤–µ—â–∞–Ω–∏—è, –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é –ø—Ä–æ—Ç–æ–∫–æ–ª."
    )

def main() -> None:
    """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.AUDIO, handle_audio))
    
    application.run_polling()
    logger.info("–ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω")

if __name__ == "__main__":
    main()